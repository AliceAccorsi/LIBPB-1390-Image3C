{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0571f1",
   "metadata": {},
   "source": [
    "## Training the classifier\n",
    "\n",
    "Use this notebook to train the image3c classifier using the clusters assigned previously\n",
    "as labels for classes.\n",
    "\n",
    "Before running this notebook, the [Image Pre-processing](image_preprocessing.ipynb) notebook needs to be run\n",
    "to save the images for training into the right format and to create a file with\n",
    "the cluster IDs as labels from the clustering results.\n",
    "\n",
    "To perform the training we only need to import image3c.network_training.\n",
    "\n",
    "This notebook creates a dictionary of parameters to tell the trainer where to\n",
    "find images and labels, where to save the trained network, and other network\n",
    "parameters.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "The source Python code for the image3c classifier can be found on Github: [Image3c source](https://github.com/stowersinstitute/LIBPB-1390-Image3C/tree/master/Code/Classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from image3c import network_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the operating system separator to use in paths to avoid file errors\n",
    "\n",
    "slash = os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d2ea5",
   "metadata": {},
   "source": [
    "### Create the parameter dictionary\n",
    "\n",
    "- description :   Description of the experiment\n",
    "- num_classes :   Number of clusters found with Vortex clustering\n",
    "- datafile :      Location of the datafile in numpy format (from [imageprep.ipynb](imageprep.ipynb))\n",
    "- labelsfile :    Location of the file with class labels (from [imageprep.ipynb](imageprep.ipynb))\n",
    "- CheckpointDir : Location to save intermediate and final models\n",
    "- num_channels :  Number of channels in the dataset.\n",
    "- channels :      List of channels to be used for training, i.e., [0, 1, 2] or [1,2,4] if you want subset of channels.\n",
    "- iterations :   Number iterations to perform. Around 25,000 seems to work well\n",
    "- batchsize  :   Number of images in an iteration. This depends on the memory of your system or GPU. Start with 256 and decrease it if memory errors are experienced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884694f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['description'] = \"Training description\" ## Description for your training\n",
    "\n",
    "## Number of classes, typically the same as the number of classes found previously in Vortex\n",
    "num_classes = 7  \n",
    "\n",
    "# path to the numpy file with images\n",
    "params['datafile'] = 'Data/snail_images.npy'\n",
    "\n",
    "# path to numpy file with cluster labels\n",
    "params['labelsfile'] = 'Data/snail_labels.npy'\n",
    "\n",
    "# path to checkpoints\n",
    "params['CheckpointDir'] = \"Checkpoints/test\"\n",
    "\n",
    "# the number of channels in the images\n",
    "params['num_channels'] = 5\n",
    "\n",
    "# channels to use. Start at zero!\n",
    "params['channels'] = [0,2,4]\n",
    "\n",
    "# channel to combine\n",
    "params['combine'] = [[0,8], [4,7]] \n",
    "\n",
    "params['clusterlist'] = list(range(num_classes))\n",
    "\n",
    "\n",
    "params['iterations'] = 25000 #25000\n",
    "params['learning_rate'] = 0.001 #0.0006\n",
    "params['droprate'] = 0.0\n",
    "params['l2f'] = 0.006 #0.004\n",
    "params['batchsize'] = 256\n",
    "params['tensorboard_log_dir'] = 'logs'\n",
    "### Name of output checkpoint directory\n",
    "\n",
    "if not params['CheckpointDir'].endswith(slash):\n",
    "    params['CheckpointDir'] += slash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263c416",
   "metadata": {},
   "source": [
    "### Run the training\n",
    "\n",
    "Now the network can be trained with `network_training.run()`.\n",
    "\n",
    "#### Testing and validattion\n",
    "10 percent of the images are held out for testing during the training and another 10 percent as held out for validation after the training. The images and labels for validation are saved as a numpy files in the `CheckpointDir` folder defined above.\n",
    "\n",
    "#### Normalization\n",
    "The images for training are normalized to have zero mean and a standard deviation of one. It is important to perform this normalization on images to be predicted after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_training.run(params)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9111aab",
   "metadata": {},
   "source": [
    "### Post-training\n",
    "\n",
    "After the training is complete, model files called checkpoints are save in `CheckpointDir` defined in the parameters. A checkpoint is created for the training iteration with the best accuaracy, and a checkpoint for the final training iteration. An example of using a checkpoint can be found in [performance testing](performance_testing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05193bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image3c",
   "language": "python",
   "name": "image3c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
