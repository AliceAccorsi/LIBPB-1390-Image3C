{
    "collab_server" : "",
    "contents" : "library(flowCore)\nlibrary(flowStats)\nlibrary(ggcyto)\nlibrary(ggridges)\nlibrary(stringr)\nlibrary(Hmisc)\nlibrary(caret)\nlibrary(pheatmap)\nlibrary(reshape2)\nlibrary(data.table)\nlibrary(RColorBrewer)\nsource(\"AuxFunctions.R\") #sources functions from this file in same directory\n\n\n###############################\n#read in files, pull out some header data etc that we'll need\nmyflowset <- read.flowSet(pattern = \".fcs\", path = \".\", alter.names = TRUE, transformation = FALSE, emptyValue = FALSE) #read all fcs files in current dir to flowset\nmycolnames <- as.character(colnames(exprs(myflowset[[4]]))) #get all channel names\nautoplot(myflowset[[4]]) #use \"snail1_phago\"\n\n#generate clustering heatmap of feature correlation from a frame in the set\nmyframe <- myflowset[[4]] #pull out a single flow frame\nmat <- exprs(myframe) #extract matrix\ncor_mat <- cor(mat, method = \"spearman\") #get correlation matrix\npheatmap(cor_mat) #plot it using clustering heatmaps\n\n#####\n#remove redundant features based on correlation\n#####\n\nmyfrm <- data.frame(exprs(myframe)) #convert data from 1st sample to data frame object\nfrmTrim <- DaMiR.FReduct(myfrm, th.corr = 0.85) #removes features with Cor values > 0.85\ncolstrimmed <- colnames(frmTrim) #get names of remaining features\ntoremove <- setdiff(mycolnames, colstrimmed) #set operation to find difference with total\n\nmyflowset <- dropSet(myflowset, toremove)\n\n#generate new clustering heatmap \nmyframe <- myflowset[[4]] #pull out a single flow frame\nmat <- exprs(myframe) #extract matrix\ncor_mat <- cor(mat, method = \"spearman\") #get correlation matrix\npheatmap(cor_mat) #plot it using clustering heatmaps\n\n#sample correlations by feature means\nmyMeans <- extractMeans(myflowset) #get a list of features means, one list item per file\nmyMeans <- rbindlist(myMeans) #combine to one big table\nmyMeans <- dcast(myMeans, Sample ~ Feature, value.var = \"Means\") #recast to wide form\nrownames(myMeans) <- myMeans$Sample #rename rownames\nmyMeans[,1] <- NULL #remove redundant col\n#convert all to numeric\nmyMeans[] <- lapply(myMeans, function(x) {\n  if(is.factor(x)) as.numeric(as.character(x)) else x\n})\n\nmeansMat <- as.matrix(myMeans) #convert to matrix\nrownames(meansMat) <- rownames(myMeans)\nmeansMat[!is.finite(meansMat)] #check for infinite values\nwrite.csv(rownames(meansMat), file=\"NamesToGroup.csv\") #save table to manually annotate things if needed\nrowAnnot <- read.csv(file=\"RowLabels.csv\")\nrownames(rowAnnot) <- rownames(meansMat) #put rownames from means table\nrowAnnot[,1] <- NULL #remove redudant column\nsetdiff(myflowset@phenoData@data$names,rowAnnot$X) #check that sample names match, should return NULL\n\n\npheatmap(meansMat, scale = \"column\", annotation_row = rowAnnot) #make clustering heatmap of feature means per sample\nbreaksList <- seq(0.9,1, by = 0.01)\npheatmap(cor(t(meansMat)), annotation_row = rowAnnot[,c(1:3)],\n         color = colorRampPalette(rev(brewer.pal(n = 10, name = \"RdYlBu\")))(length(breaksList)),\n         breaks = breaksList) #heatmap of correlation \npheatmap(cor(t(meansMat)))\n\n####\n#remove outlier samples\n####\n\n# meansCor <- cor(t(meansMat)) #correlation on transposted means matrix\n# tokeep <- findCorrelation(meansCor, cutoff = 0.95, names = FALSE) #list of samples with mean cor >0.9\n# tokeepnames <- findCorrelation(meansCor, cutoff = 0.9, names = TRUE) #same but return names not index\n# myflowset <- myflowset[c(tokeep)] #subset flowset to remove low cor samples\n# rowAnnot <- rowAnnot[tokeepnames,] #remove dropped samples from annotation data\n# rowAnnot <- as.data.frame(rowAnnot)\n# colnames(rowAnnot) <- \"Desc\"\n# rownames(rowAnnot) <- myflowset@phenoData@data$name\n# \n# #sample correlations by feature means, do again w/out outliers\n# myMeans <- extractMeans(myflowset) #get a list of features means, one list item per file\n# myMeans <- rbindlist(myMeans) #combine to one big table\n# myMeans <- dcast(myMeans, Sample ~ Feature, value.var = \"Means\") #recast to wide form\n# rownames(myMeans) <- myMeans$Sample #rename rownames\n# myMeans[,1] <- NULL #remove redundant col\n# #convert all to numeric\n# myMeans[] <- lapply(myMeans, function(x) {\n#   if(is.factor(x)) as.numeric(as.character(x)) else x\n# })\n# \n# meansMat <- as.matrix(myMeans) #convert to matrix\n# rownames(meansMat) <- rownames(myMeans)\n# meansMat[!is.finite(meansMat)] #check for infinite values\n# setdiff(myflowset@phenoData@data$names,rownames(rowAnnot)) #check that sample names match, should return NULL\n# \n# pheatmap(meansMat, scale = \"column\", annotation_row = rowAnnot) #make clustering heatmap of feature means per sample\n# breaksList <- seq(0.9,1, by = 0.01)\n# pheatmap(cor(t(meansMat)), annotation_row = rowAnnot,\n#          color = colorRampPalette(rev(brewer.pal(n = 10, name = \"RdYlBu\")))(length(breaksList)),\n#          breaks = breaksList) #heatmap of correlation \n# pheatmap(cor(t(meansMat)), method = \"spearman\")\n# \n#####\n#transform fluorescent parms to allow gaussNorm normalization\n#####\nmycolnames <-  colnames(myflowset[[4]]) #get new list of parm names\nautoplot(myflowset[[4]]) #plot all histograms\nChnlsToTrans <- mycolnames[c(15:18)] #which parms to transform\ntranslist <- estimateLogicle(myflowset[[4]], ChnlsToTrans) #estimate logicle transform from data\nmyflowsetTrans <- transform(myflowset, translist) #apply logicle transform to flowset\nautoplot(myflowsetTrans, mycolnames[19], mycolnames[21]) + geom_hex(bins=40) #have a look at some data\nautoplot(myflowsetTrans[[4]])\n\np <- ggcyto(myflowsetTrans, aes(x = 'Intensity_AdaptiveErode_BF_Ch11'))\np + geom_density_ridges(aes(y = as.factor(name))) + facet_null()\n\n#####\n#scale and center flow frames in set, one by one not merged\n#only do for DNA intensity on this set\n#####\n\nmycolnames <- colnames(myflowset[[4]])\n\nflowsetScaled <- scaleDNA(myflowsetTrans)\n\n#Snail3_Phago_18 has abnormal draq5 staining, will remove it\ntokeep <- myflowset@phenoData@data$name\ntokeep <- tokeep[c(1:11,13:20)]\nflowsetScaled <- flowsetScaled[c(tokeep)]  #Remove that sample (keep all but index 12 in list of names)\n\n#Check DNA content histograms before scaling data\np <- ggcyto(myflowsetTrans, aes(x = 'Intensity_AdaptiveErode_BF_Ch11'))\np + geom_density_ridges(aes(y = as.factor(name))) + facet_null() #+ xlim(c(-3,3))\n\n\n#plot stacked histograms of transformed, orig data\np <- ggcyto(flowsetScaled, aes(x = 'Intensity_AdaptiveErode_BF_Ch02'))\np + geom_density_ridges(aes(y = as.factor(name))) + facet_null()\n\np2 <- ggcyto(flowsetScaled, aes(x = 'Intensity_AdaptiveErode_BF_Ch07'))\np2 + geom_density_ridges(aes(y = as.factor(name))) + facet_null()\n\np3 <- ggcyto(flowsetScaled, aes(x = 'Intensity_AdaptiveErode_BF_Ch11'))\np3 + geom_density_ridges(aes(y = as.factor(name))) + facet_null() + xlim(c(-3,3))\n\n\n\n#use gaussNorm functino from flowStats to normalize each channel across files\nmaxlms <- c(2)\nChnlsToNorm <- mycolnames[18] #Intensity CTV, Max Pixel draq5\nnormResult <- gaussNorm(flowsetScaled, channel.names = ChnlsToNorm,\n                        max.lms = maxlms,\n                        peak.distance.thr = 0.1,\n                        peak.density.thr = 0.05) #normalize DNA parm\n\nmyflowsetNorm <- normResult$flowset #pull out flowset from returned object\n\np2 <- ggcyto(myflowsetNorm, aes(x = 'Intensity_AdaptiveErode_BF_Ch11'))\np2 + geom_density_ridges(aes(y = as.factor(name))) + facet_null() + xlim(c(-3,3))\n\n\n# #can do again with different settings if above doesn't work for some params\n# maxlms <- c(2)\n# ChnlsToNorm <- mycolnames[c(16)] #Intensity DHR\n# normResult <- gaussNorm(myflowsetNorm, channel.names = ChnlsToNorm,\n#                         max.lms = maxlms,\n#                         peak.distance.thr = 0.2,\n#                         peak.density.thr = 0.05) #normalize DNA parm\n# \n# myflowsetNorm1 <- normResult$flowset #pull out flowset from returned object\n# \n# \n# p3 <- ggcyto(myflowsetNorm1, aes(x = 'Intensity_AdaptiveErode_BF_Ch02'))\n# p3 + geom_density_ridges(aes(y = as.factor(name))) + facet_null()\n\n##and one more time\n\n# maxlms <- c(2)\n# ChnlsToNorm <- mycolnames[c(18)] #Intensity draq5, set using the assumption that most cells are 2n, \n# #ie, EDTA hasn't induced arrest at 4n, but should confirm.\n# normResult <- gaussNorm(myflowsetNorm, channel.names = ChnlsToNorm,\n#                         max.lms = maxlms,\n#                         peak.distance.thr = 0.3,\n#                         peak.density.thr = 0.1) #normalize DNA parm\n# \n# myflowsetNorm2 <- normResult$flowset #pull out flowset from returned object\n# \n# \n# p3 <- ggcyto(myflowsetNorm2, aes(x = 'Intensity_AdaptiveErode_BF_Ch11'))\n# p3 + geom_density_ridges(aes(y = as.factor(name))) + facet_null()\n\n\n##############Save new fcs files###############\n\n#set up file names\n\ndir <- getwd()\nmynames <- myflowsetNorm@phenoData@data$name #get file names from flowset\nmynames <- strsplit(mynames, \"\\\\.\") #string split on \".\"\nmynames <- sapply(mynames, function(x) strsplit(x, \":\")[[1]][1]) #get out 1st element from strsplit output\nmynames <- paste(mynames, \"_processed.fcs\", sep = \"\") #paste in new suffixes\n\n#save new fcs files\nwrite.flowSet(myflowsetNorm, dir, filename = mynames)\n\n\n\n\n",
    "created" : 1513696800425.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "427514670",
    "id" : "9C08CF94",
    "lastKnownWriteTime" : 1513720956,
    "last_content_update" : 1513720956268,
    "path" : "E:/17cy2193_NoCTV,CTV,ICE,EDTA/IDEAS_fcs_export/gaussNorm/NormalizeScaleDropRedundant12R.R",
    "project_path" : "NormalizeScaleDropRedundant12R.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}